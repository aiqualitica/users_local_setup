# TestCase Generation Platform - Local Setup

This folder contains everything you need to run the TestCase Generation Platform locally.

## ğŸ“ Files Included

- `docker-compose_cpu_standalone.yml` - Docker Compose configuration for standalone deployment
- `nginx.standalone.conf` - Nginx configuration for reverse proxy
- `init_versioning_db.py` - Database initialization script
- `setup_cluster.sh` - Automated setup script
- `README.md` - This documentation

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop installed and running
- Docker Compose installed
- Python 3.x installed

### ğŸ” Required Setup (Before Running)

**1. Create a `.env` file with these 4 essential variables:**
```bash
# Create environment file
touch .env
```

**2. Add these 4 required variables to `.env`:**
```env
# Google OAuth (get from: https://console.cloud.google.com/)
GOOGLE_CLIENT_ID=your_google_client_id_here
GOOGLE_CLIENT_SECRET=your_google_client_secret_here

# JWT Secret (any string works)
JWT_SECRET=your_jwt_secret_here

# OpenAI API Key (get from: https://platform.openai.com/)
LLM_API_KEY=your_openai_api_key_here
```

**3. Get your credentials:**
- **Google OAuth:** [Google Cloud Console](https://console.cloud.google.com/) â†’ Create OAuth 2.0 Client ID
- **OpenAI API:** [OpenAI Platform](https://platform.openai.com/) â†’ Get API Key
- **JWT Secret:** Can be any string (e.g., "myapp123" or generate with `openssl rand -base64 32`)

### One-Command Setup
```bash
chmod +x setup_cluster.sh
./setup_cluster.sh
```

This script will:
1. âœ… Create Python virtual environment
2. âœ… Install required dependencies
3. âœ… Start Docker Compose cluster
4. âœ… Wait for services to be ready
5. âœ… Initialize database schema
6. âœ… Display cluster status

## ğŸŒ Access Points

After successful setup:
- **Main Application:** http://localhost
- **RabbitMQ Management:** http://localhost:15672
- **Neo4j Browser:** http://localhost:7474
- **Qdrant Dashboard:** http://localhost:6333/dashboard

## ğŸ› ï¸ Manual Setup (Alternative)

If you prefer to run commands manually:

### 1. Start the Cluster
```bash
docker-compose -f docker-compose_cpu_standalone.yml up -d
```

### 2. Wait for PostgreSQL
```bash
# Wait for PostgreSQL to be ready
docker-compose -f docker-compose_cpu_standalone.yml exec postgres pg_isready -U postgres
```

### 3. Initialize Database
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install psycopg2-binary

# Run database initialization
python3 init_versioning_db.py
```

## ğŸ›‘ Stop the Cluster

```bash
docker-compose -f docker-compose_cpu_standalone.yml down
```

## âš™ï¸ Advanced Configuration (Optional)

### Custom Environment Variables
You can customize these optional settings in your `.env` file:

```env
# Database Configuration (defaults work for local setup)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=testcase_db
DB_USER=postgres
DB_PASSWORD=password

# Custom Ports (optional)
TESTCASE_MANAGER_PORT=8000
API_LAYER_PORT=8001
LLM_SERVICE_PORT=8002
# ... other ports
```

### Custom Docker Compose Settings
- Edit `docker-compose_cpu_standalone.yml` for advanced Docker configurations
- Modify `nginx.standalone.conf` for custom Nginx settings
- Update `init_versioning_db.py` for database schema changes

## ğŸ”§ Troubleshooting

### Check Service Status
```bash
docker-compose -f docker-compose_cpu_standalone.yml ps
```

### View Logs
```bash
docker-compose -f docker-compose_cpu_standalone.yml logs [service-name]
```

### Restart Services
```bash
docker-compose -f docker-compose_cpu_standalone.yml restart [service-name]
```

### Environment Variables Issues
If you see authentication errors:
1. **Check your `.env` file exists and has all required variables**
2. **Verify Google OAuth credentials are correct**
3. **Ensure OpenAI API key is valid and has credits**
4. **Check JWT_SECRET is set (can be any string)**

### Common Issues
- **"Authentication service unavailable"** â†’ Check IAM service logs
- **"Google OAuth failed"** â†’ Verify GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET
- **"LLM service error"** â†’ Check LLM_API_KEY and OpenAI account
- **"Database connection failed"** â†’ Ensure PostgreSQL container is running

## ğŸ“Š Services Included

- **PostgreSQL** (Port 5432) - Database
- **Redis** (Port 6379) - Caching
- **RabbitMQ** (Ports 5672, 15672) - Message Queue
- **Neo4j** (Ports 7474, 7687) - Graph Database
- **Qdrant** (Port 6333) - Vector Database
- **API Gateway** (Port 8001) - Main API
- **IAM Service** (Port 8007) - Authentication
- **LLM Service** (Port 8002) - AI/ML Processing
- **Nginx** (Ports 80, 443) - Reverse Proxy

## ğŸ¯ Features

- âœ… **Complete Test Case Management**
- âœ… **AI-Powered Test Case Generation**
- âœ… **TCM Integrations** (TestRail, Zephyr, Xray)
- âœ… **Subscription Management**
- âœ… **Multi-tenant Architecture**
- âœ… **Version Control**
- âœ… **Google OAuth Authentication**

## ğŸ“ Notes

- The setup script automatically handles all dependencies
- Database is initialized with default subscription plans
- All services are configured for local development
- No external dependencies required (except Docker)

## ğŸ†˜ Support

If you encounter any issues:
1. Check that Docker Desktop is running
2. Verify all ports are available
3. Check service logs for specific errors
4. Ensure you have sufficient disk space (images are ~4GB total)
